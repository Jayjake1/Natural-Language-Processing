Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer 
   -> https://arxiv.org/abs/1910.10683

Reformer: The Efficient Transformer 
   -> https://arxiv.org/abs/2001.04451

Attention Is All You Need
   -> https://arxiv.org/abs/1706.03762

Deep contextualized word representations
   -> https://arxiv.org/pdf/1802.05365.pdf

The Illustrated Transformer 
   -> http://jalammar.github.io/illustrated-transformer/

The Illustrated GPT-2 (Visualizing Transformer Language Models)
   -> http://jalammar.github.io/illustrated-gpt2/

BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding 
   -> https://arxiv.org/abs/1810.04805

How GPT3 Works - Visualizations and Animations
   -> http://jalammar.github.io/how-gpt3-works-visualizations-animations/

